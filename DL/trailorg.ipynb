{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"conv2d_daily.npy\")\n",
    "data = data[1:, :, :]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_info = pd.read_excel(\"../year_info.xlsx\")\n",
    "year_info.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_info[year_info[\"year\"] < 1975].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_info[year_info[\"year\"] < 1975][\"is_leap\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(74-18)*365 + 18*366"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_info[year_info[\"year\"] >= 1975][year_info[\"year\"] <= 2000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_info[year_info[\"year\"] >= 1975][year_info[\"year\"] <= 2000][\"is_leap\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(26-7)*365 + 7*366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1975_2000 = data[27028: 27028+9497]\n",
    "data_1975_2000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.expand_dims(data_1975_2000, axis=-1)\n",
    "dataset = np.expand_dims(dataset, axis=0)\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_shifted_frames(data):\n",
    "#     x = data[0 : data.shape[0] - 1, :, :]\n",
    "#     y = data[ 1 : data.shape[0], :, :]\n",
    "#     return x, y\n",
    "\n",
    "def create_shifted_frames(data):\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    y = data[:, 1 : data.shape[1], :, :]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_shifted_frames(dataset)\n",
    "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=(None, *x_train.shape[2:])\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the input layer with no definite frame size.\n",
    "inp = tf.keras.layers.Input(shape=(None, *x_train.shape[2:]))\n",
    "\n",
    "# We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
    "# followed by a `Conv3D` layer for the spatiotemporal outputs.\n",
    "x = tf.keras.layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(5, 5),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(inp)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(1, 1),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = tf.keras.layers.Conv3D(\n",
    "    filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
    ")(x)\n",
    "\n",
    "# Next, we will build the complete model and compile it.\n",
    "model = tf.keras.models.Model(inp, x)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modifiable training hyperparameters.\n",
    "epochs = 5\n",
    "batch_size = 5\n",
    "\n",
    "# Fit the model to the training data.\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a99892a7141c01cf7e15ac41e161bc09a8ab59897b5ddbc04e576bb3744408a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
